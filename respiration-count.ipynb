{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'you can download /kaggle/input/respiration-count-video/testOne.mp4 video to see output of algorithm  '","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:45:31.118636Z","iopub.execute_input":"2023-05-19T12:45:31.119044Z","iopub.status.idle":"2023-05-19T12:45:31.126193Z","shell.execute_reply.started":"2023-05-19T12:45:31.119011Z","shell.execute_reply":"2023-05-19T12:45:31.125025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install mediapipe\nimport cv2\nimport os\nimport mediapipe as mp\nimport numpy as np\nimport time\n\ncountNonZero=[]\n\ncap= cv2.VideoCapture(0)\n\nobject_tracker=cv2.createBackgroundSubtractorMOG2(history=100,varThreshold=10)\n\nmp_drawing = mp.solutions.drawing_utils\nmp_drawing_styles = mp.solutions.drawing_styles\nmp_pose = mp.solutions.pose\nframe_width = int(cap.get(3))\nframe_height = int(cap.get(4))\nforcc=cv2.VideoWriter_fourcc(*'XVID')\nsize = (frame_width, frame_height)\n\nout=cv2.VideoWriter('output.mp4',forcc,20.0,(300,300))\nRespiration_count=0\nwith mp_pose.Pose(\n    min_detection_confidence=0.5,\n    min_tracking_confidence=0.5) as pose:\n  \n\n\n  while cap.isOpened():\n    \n    success, image = cap.read()\n\n    if success==True:\n\n        # To improve performance, optionally mark the image as not writeable to\n        # pass by reference.\n        #image.flags.writeable = False\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = pose.process(image)\n\n        if not(results.pose_landmarks):\n            print(0)\n            continue\n        # Draw the pose annotation on the image.\n\n        image.flags.writeable = True\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n        chest_landmark_x=[]\n        chest_landmark_y=[]\n        for i in [11,12,24,23]:\n            x,y=results.pose_landmarks.landmark[i].x,results.pose_landmarks.landmark[i].y\n            h, w, c = image.shape\n            cx, cy = int(x * w), int(y * h)\n            chest_landmark_x.append(cx)\n            chest_landmark_y.append(cy)\n        image=cv2.GaussianBlur(image,(5,5),0)\n\n        mask=object_tracker.apply(image)\n        chest=mask[min(chest_landmark_y):max(chest_landmark_y),min(chest_landmark_x):max(chest_landmark_x)]\n        print(chest)\n\n        k=np.ones((2,2),np.uint8)\n        _,THRESH_BINARY=cv2.threshold(chest,254,255,cv2.THRESH_BINARY)\n        erode=cv2.erode(THRESH_BINARY,k,iterations=1)\n\n\n        countNonZero.append( cv2.countNonZero(erode))\n\n        if len(countNonZero)>=6:\n                if countNonZero[-2]<100 and (countNonZero[-1]-countNonZero[-2]>100 ):# are according to the distance of the camera from the patient\n                    Respiration_count+=1\n                   \n                   \n        cv2.putText(image,'Number of Respiration ',(10,170),cv2.FONT_HERSHEY_PLAIN,1,(255, 0, 0),2) \n\n        cv2.putText(image,f'{Respiration_count}',(10,210),cv2.FONT_HERSHEY_PLAIN, 3,(255, 0, 0), 3)    \n  \n        cv2.imshow('mask',mask)\n        cv2.imshow('dilation',chest)\n\n        out.write(image)\n        cv2.imshow('MediaPipe Pose',image)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    else :\n        break\n    \ncap.release()\nout.release()\ncv2.destroyAllWindows()\n","metadata":{},"execution_count":null,"outputs":[]}]}